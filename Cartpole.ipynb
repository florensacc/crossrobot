{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "theano.config.exception_verbosity='high'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: pure python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Simulates cartpole starting at x0 with action u -- ported from CS287 Matlab code\n",
    "'''\n",
    "\n",
    "def sim_cartpole(x0, u, dt):\n",
    "    \n",
    "    def dynamics(x, u):\n",
    "        mc = 10\n",
    "        mp = 1\n",
    "        l = 0.5\n",
    "        g = 9.81\n",
    "        T = 0.25\n",
    "        s = np.sin(x[1])\n",
    "        c = np.cos(x[1])\n",
    "        \n",
    "        xddot = (u + np.multiply(mp*s, l*np.power(x[3],2) + g*c))/(mc + mp*np.power(s,2))\n",
    "        tddot = (-u*c - np.multiply(np.multiply(mp*l*np.power(x[3],2), c),s) - \n",
    "                 np.multiply((mc+mp)*g,s)) / (l * (mc + np.multiply(mp, np.power(s,2))))\n",
    "        xdot = x[2:4]\n",
    "        xdot = np.append(xdot, xddot)\n",
    "        xdot = np.append(xdot, tddot)\n",
    "        \n",
    "        return xdot\n",
    "    \n",
    "    DT = 0.1\n",
    "    t = 0\n",
    "    while t < dt:\n",
    "        current_dt = min(DT, dt-t)\n",
    "        x0 = x0 + current_dt * dynamics(x0, u)\n",
    "        t = t + current_dt\n",
    "    \n",
    "    return x0\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Linearizes the dynamics of cartpole around a reference point for use in an LQR controler\n",
    "'''\n",
    "\n",
    "def linearize_cartpole(x_ref, u_ref, dt, eps):\n",
    "    A = np.zeros([4,4])\n",
    "\n",
    "    for i in range(4):\n",
    "        increment = np.zeros([4,])\n",
    "        increment[i] = eps\n",
    "        A[:,i] = (sim_cartpole(x_ref + increment, u_ref, dt) - \n",
    "                  sim_cartpole(x_ref, u_ref, dt)) / (eps)\n",
    "    \n",
    "    B = (sim_cartpole(x_ref, u_ref + eps, dt) - sim_cartpole(x_ref, u_ref, dt)) / (eps)\n",
    "    \n",
    "    c = x_ref\n",
    "    \n",
    "    return A, B, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Computes the LQR infinte horizon controller associated with linear dyamics A, B and quadratic cost Q, R\n",
    "\n",
    "NOTE: Current version only works for cartpole because I hardcoded a couple of numbers for now\n",
    "'''\n",
    "\n",
    "def lqr_infinite_horizon(A, B, Q, R):\n",
    "    nA = A.shape[0]\n",
    "\n",
    "    if len(B.shape) == 1:\n",
    "        nB = 1\n",
    "    else:\n",
    "        nB = B.shape[1]\n",
    "\n",
    "    P_current = np.zeros([nA, nA])\n",
    "\n",
    "    P_new = np.eye(nA)\n",
    "\n",
    "    K_current = np.zeros([nB, nA])\n",
    "\n",
    "    K_new= np.triu(np.tril(np.ones([nB,nA]),0),0)\n",
    "\n",
    "    while np.linalg.norm(K_new - K_current, 2) > 1E-4:\n",
    "        P_current = P_new\n",
    "      \n",
    "        K_current = K_new\n",
    "        \n",
    "        K_new = -np.linalg.inv(R + np.dot(np.dot( np.transpose(B), \n",
    "                                                  P_current), \n",
    "                                                  B)) * np.dot(np.dot( np.transpose(B), \n",
    "                                                                       P_current), \n",
    "                                                                       A)\n",
    "\n",
    "        P_new = Q + np.dot(np.dot( np.transpose(K_new), \n",
    "                                   R), \n",
    "                                   K_new) + np.dot(np.dot( np.transpose(A + np.dot(B.reshape(4,1), K_new)),\n",
    "                                                           P_current),\n",
    "                                                           (A + np.dot(B.reshape(4,1), K_new.reshape(1,4)))\n",
    "                          )\n",
    "        \n",
    "    return K_new, P_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_ref = np.array([0, np.pi, 0, 0])\n",
    "A, B, c = linearize_cartpole(x_ref, 0, 0.1, 0.1)\n",
    "Q = np.eye(4)\n",
    "R = np.eye(1)\n",
    "\n",
    "K_inf, P_inf = lqr_infinite_horizon(A, B, Q, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Basic implementation of a feed forward neural network with a single hidden layer. \n",
    "\n",
    "Takes input, a 1-d parameter vector, an activation function, and numbers of neurons at each layer. The parameter \n",
    "vector should be encoded as [W1.flatten(); B1; W2.flatten(); B2] where the Ws and Bs are the matrix weights and \n",
    "offset vectors. Activation function for the output layer is assumed to be linear.\n",
    "\n",
    "'''\n",
    "\n",
    "def simpleFeedForward(input, params, n_in, n_hidden, n_out, activation=np.tanh):\n",
    "    \n",
    "    ## Reshape our parameters to be used to calculate the output\n",
    "    \n",
    "    w1 = params[0 : n_in*n_hidden].reshape(n_hidden, n_in)\n",
    "    b1 = params[n_in*n_hidden : n_in*n_hidden + n_hidden]\n",
    "    w2 = params[n_in*n_hidden + n_hidden : n_in*n_hidden + n_hidden + n_hidden * n_out].reshape(n_out, n_hidden)\n",
    "    b2 = params[n_in*n_hidden + n_hidden + n_hidden * n_out:]\n",
    "    \n",
    "    lin_midstep = np.dot(w1, input) + b1\n",
    "    if activation == None:\n",
    "        midstep = lin_midstep\n",
    "    else: \n",
    "        midstep = activation(lin_midstep)\n",
    "    \n",
    "    output = np.dot(w2, midstep) + b2\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to evaluate the total penalty associated with a parameter vector theta for our simple feed forward network.\n",
    "\n",
    "Simulates cartpole with the controller given by theta and computes the sum of costs, which are assumed to be a \n",
    "quadratic form of the distance from the current position x to the target position.\n",
    "\n",
    "'''\n",
    "\n",
    "def evaluate_theta(start, target, T, Q, params, n_in, n_hidden, n_out):\n",
    "\n",
    "    dt = 0.1\n",
    "    \n",
    "    u = np.zeros(T)\n",
    "    x = np.zeros([n_in, T+1])\n",
    "    x[:, 0] = start\n",
    "    for t in range(T):\n",
    "        u[t] = simpleFeedForward(x[:, t], params, n_in, n_hidden, n_out)\n",
    "        x[:, t+1] = sim_cartpole(x[:,t], u[t], dt)\n",
    "    \n",
    "    x_diff = x - np.transpose(np.tile(target, (x.shape[1],1)))\n",
    "    penalty =  np.sum(np.diag(np.dot(np.transpose(x_diff), np.dot(Q, x_diff))))\n",
    "    \n",
    "    return penalty, x, u\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/kernel/__main__.py:13: RuntimeWarning: overflow encountered in power\n",
      "/usr/local/lib/python2.7/site-packages/IPython/kernel/__main__.py:14: RuntimeWarning: overflow encountered in power\n",
      "/usr/local/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: RuntimeWarning: invalid value encountered in sin\n",
      "/usr/local/lib/python2.7/site-packages/IPython/kernel/__main__.py:11: RuntimeWarning: invalid value encountered in cos\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Some code to try to run policy gradient. Does not work yet - blows up to NaNs.\n",
    "\n",
    "'''\n",
    "\n",
    "##\n",
    "## Initialize our variables\n",
    "##\n",
    "rng = np.random.RandomState(1234)\n",
    "input = np.array([0, np.pi - np.pi/10, 0, 0])\n",
    "n_in = 4\n",
    "n_hidden = 20\n",
    "n_out = 1\n",
    "\n",
    "W1 = np.asarray(\n",
    "                rng.uniform(\n",
    "                    low = -np.sqrt(6. / (n_in + n_hidden)), \n",
    "                    high = np.sqrt(6. / (n_in + n_hidden)),\n",
    "                    size = (n_in, n_hidden)\n",
    "                ))\n",
    "\n",
    "W2 = np.asarray(\n",
    "                rng.uniform(\n",
    "                    low = -np.sqrt(6. / (n_out + n_hidden)), \n",
    "                    high = np.sqrt(6. / (n_out + n_hidden)),\n",
    "                    size = (n_hidden, n_out)\n",
    "                ))\n",
    "\n",
    "B1 = np.zeros([n_hidden,1])\n",
    "B2 = np.zeros([n_out, 1])\n",
    "\n",
    "## Cost function penalizes equal deviation from target coordinates\n",
    "target = np.array([0, np.pi, 0, 0])\n",
    "Q = np.eye(n_in)\n",
    "\n",
    "def penalty(x):\n",
    "    if len(x.shape) == 1:\n",
    "        return np.dot(x-target,np.dot(Q, x-target))\n",
    "    else:\n",
    "        x_diff = x - np.transpose(np.tile(target, (x.shape[1],1)))\n",
    "        return np.sum(np.diag(np.dot(np.transpose(x_diff), np.dot(Q, x_diff))))\n",
    "    \n",
    "\n",
    "\n",
    "params = np.append(np.append(np.append(W1.flatten(), B1), W2.flatten()), B2)\n",
    "\n",
    "max_iter = 100\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "epsilon = 0.1\n",
    "\n",
    "penalties = np.zeros(max_iter)\n",
    "\n",
    "for i in range(max_iter):\n",
    "    \n",
    "    ## Generate trajectory to evaluate our policy\n",
    "\n",
    "    start = np.array([0, np.pi - np.pi/10, 0, 0])\n",
    "    \n",
    "    penalties[i], x, u = evaluate_theta(start, target, 500, Q, params, n_in, n_hidden, n_out)\n",
    "        \n",
    "    ## Perform stochastic gradient descent\n",
    "    \n",
    "    # Choose random parameter to update\n",
    "    direction = np.random.randint(0, len(params))\n",
    "    \n",
    "    unitv = np.zeros(len(params))\n",
    "    unitv[direction] = epsilon\n",
    "    \n",
    "    # Calculate the penalty in that direction\n",
    "    new_penalty, x, u = evaluate_theta(start, target, 500, Q, params + unitv, n_in, n_hidden, n_out)\n",
    "    \n",
    "    partial_x = unitv\n",
    "    partial_x[direction] = (new_penalty - penalties[i])/epsilon\n",
    "    \n",
    "    ## Update the parameter vector\n",
    "    params = params - learning_rate * partial_x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Theano code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of hidden layer class. Modified from here: http://deeplearning.net/tutorial/mlp.html#mlp.\n",
    "\n",
    "Note: I changed feeding forward to a function because I couldn't figure out how to update the internal state 'input'\n",
    "    when iterating to generate paths. May be better to switch back to that in the long run to make more layers\n",
    "    easier to link together?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class HiddenLayer(object):\n",
    "    def __init__(self, rng, n_in, n_out, W=None, b=None, activation=T.tanh):\n",
    "        self.input = input\n",
    "        \n",
    "        if W is None:\n",
    "            W_values = np.asarray(\n",
    "                rng.uniform(\n",
    "                    low = -np.sqrt(6. / (n_in + n_out)), \n",
    "                    high = np.sqrt(6. / (n_in + n_out)),\n",
    "                    size = (n_in, n_out)\n",
    "                ),\n",
    "                dtype = theano.config.floatX)\n",
    "            if activation == theano.tensor.nnet.sigmoid:\n",
    "                W_values *= 4\n",
    "                \n",
    "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
    "            \n",
    "        if b is None:\n",
    "            b_values = np.zeros((n_out,), dtype = theano.config.floatX)\n",
    "            b = theano.shared(value = b_values, name='b', borrow=True)\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "        self.activation = activation\n",
    "        \n",
    "    def feed_forward(self, input):\n",
    "        lin_output = T.dot(input, self.W) + self.b\n",
    "        output = (\n",
    "            lin_output if self.activation is None\n",
    "            else self.activation(lin_output)\n",
    "        )\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Class wrapper for our basic feed forward network in Theano. \n",
    "\n",
    "Modified from here: http://deeplearning.net/tutorial/mlp.html#mlp.\n",
    "\n",
    "Note: similar to above, modified to make feed-forward a function in the main version\n",
    "'''\n",
    "\n",
    "class SingleLayerNet(object):\n",
    "    \n",
    "    def __init__(self, rng, n_in, n_hidden, n_out):\n",
    "        \n",
    "        dt = 0.1  ## Delete?\n",
    "        \n",
    "        num_steps = 10  ## Delete?\n",
    "        \n",
    "        self.hiddenLayer = HiddenLayer(\n",
    "            rng = rng,\n",
    "            n_in = n_in, \n",
    "            n_out = n_hidden, \n",
    "            activation = T.tanh\n",
    "        )\n",
    "        \n",
    "        self.outputLayer = HiddenLayer(\n",
    "            rng = rng,\n",
    "            n_in = n_hidden,\n",
    "            n_out = n_out,\n",
    "            activation = None\n",
    "        )\n",
    "             \n",
    "        \n",
    "        ## L1 and L2 regularization. Not used for now.\n",
    "        self.L1 = ( abs(self.hiddenLayer.W).sum() + abs(self.outputLayer.W).sum() )\n",
    "        \n",
    "        self.L2_sqr = ( (self.hiddenLayer.W ** 2).sum() + (self.outputLayer.W ** 2).sum())\n",
    "        \n",
    "        ## Don't think notion of errors makes sense\n",
    "        #self.errors = self.logRegressionLayer.errors\n",
    "        \n",
    "        self.params = self.hiddenLayer.params + self.outputLayer.params\n",
    "        \n",
    "        \n",
    "    def feed_forward(self, input):\n",
    "        return self.outputLayer.feed_forward(self.hiddenLayer.feed_forward(input))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Theano variables for input to our functions below\n",
    "C = T.scalar('C')\n",
    "Q = T.matrix('Q')\n",
    "num_steps = T.iscalar('num_steps')\n",
    "x_t = T.vector('x_t')\n",
    "learning_rate = theano.shared(1E-7)\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "policy = SingleLayerNet(rng, 4, 10, 1)\n",
    "\n",
    "## Global variables for cartpole dynamics updates\n",
    "mc = 10\n",
    "mp = 1\n",
    "l = 0.5\n",
    "g = 9.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "COMPUTE TRAJECTORY\n",
    "'''\n",
    "## Compute the cartpole dyanmics updates\n",
    "def calc_step(x, u, dt):\n",
    "    xdot = T.concatenate( [\n",
    "                x[2:4], \n",
    "                (u + mp*T.sin(x[1])*(l*x[3]**2 + g*T.cos(x[1])))/(mc + mp*T.sin(x[1])**2),\n",
    "                (-u*T.cos(x[1]) -(mp*l*x[3]**2) * T.cos(x[1]) * T.sin(x[1]) - \n",
    "                     (mc+mp)*g* T.sin(x[1])) / (l * (mc + mp * T.sin(x[1]) ** 2))\n",
    "            ])\n",
    "    \n",
    "    return x + dt * xdot\n",
    "\n",
    "## Symbolically compute the trajectory associated with the policy encoded in our network\n",
    "gen_traj, traj_update = theano.scan(\n",
    "    lambda x, u, cost, dt, Q, x_t: [\n",
    "        calc_step(x,u,dt), \n",
    "        policy.feed_forward(calc_step(x,u,dt)), \n",
    "        T.dot(T.dot(x - x_t, Q), x-x_t)\n",
    "    ],\n",
    "    outputs_info = [x, policy.feed_forward(x), T.ones_like(C)],\n",
    "    non_sequences = [dt, Q, x_t],\n",
    "    n_steps = num_steps\n",
    ")\n",
    "\n",
    "## Compiled Theano function for simulating the cartpole trajectory\n",
    "sim_cartpole_T = theano.function([x, dt, C, Q, x_t, num_steps], gen_traj, updates=traj_update) ## Can we remove C??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "SET UP GRADIENT DESCENT UPDATES\n",
    "'''\n",
    "\n",
    "# Compute the cost associated with a given trajectoy\n",
    "total_cost = T.sum(gen_traj[2])\n",
    "\n",
    "gradient = [T.grad(total_cost, param) for param in policy.params]\n",
    "\n",
    "#output = [total_cost, policy.params[0], gradient]\n",
    "\n",
    "#outputs = [total_cost, gradient]\n",
    "#outputs += [param for param in policy.params]\n",
    "\n",
    "\n",
    "updates = [(param, param - learning_rate * gparam) for param, gparam in zip(policy.params, gradient)]\n",
    "\n",
    "gradient_step = theano.function(\n",
    "    inputs= [x, dt, C, Q, x_t, num_steps], \n",
    "    outputs= total_cost, \n",
    "    updates=updates\n",
    "                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "CALC COST, NEXT STEP, AND COMPUTE GRADIENT: DEBUGGING FUNCTIONS\n",
    "'''\n",
    "\n",
    "#compute_gradient = theano.function(\n",
    "#    inputs = [x, dt, C, Q, x_t, num_steps],\n",
    "#    outputs = gradient\n",
    "#)\n",
    "\n",
    "#compute_cost = theano.function(\n",
    "#    inputs = [x, dt, C, Q, x_t, num_steps],\n",
    "#    outputs = total_cost\n",
    "#)\n",
    "\n",
    "compute_next_step = theano.function(\n",
    "    inputs = [x, u, dt],\n",
    "    outputs = calc_step(x, u, dt)\n",
    ")\n",
    "\n",
    "compute_control_input = theano.function(\n",
    "    inputs = [x],\n",
    "    outputs = policy.feed_forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "SIMULATE CARTPOLE\n",
    "'''\n",
    "\n",
    "x_traj, u_traj, c_traj = sim_cartpole_T(x0, 0.1, 1, np.eye(4), np.array([0,np.pi, 0, 0]), 100)\n",
    "\n",
    "print x_traj[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "\n",
    "x0 = np.array([0, np.pi - np.pi/10, 0, 0])\n",
    "Q0 = np.eye(4)\n",
    "x_t0 = np.array([0, np.pi, 0, 0])\n",
    "path_length = 500\n",
    "\n",
    "max_iter = 10\n",
    "tolerance = 0.1\n",
    "loss_iter = []\n",
    "\n",
    "for i in range(max_iter):\n",
    "    if (i % 10 == 0):\n",
    "        print i\n",
    "    \n",
    "    loss_iter.append(gradient_step(x = x0, \n",
    "                                   dt = 0.1,\n",
    "                                   C = 1,\n",
    "                                   Q = Q0,\n",
    "                                   x_t = x_t0,\n",
    "                                   num_steps = path_length\n",
    "                                  )\n",
    "                    )\n",
    "    \n",
    "    current_weights = policy.params\n",
    "    ## Break when the difference between successive steps is small\n",
    "    #if i > 0:\n",
    "    #    if np.abs(loss_iter[i] - loss_iter[i-1]):\n",
    "    #        break   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.40389585,  0.15987791, -0.08153353,  0.37362209,  0.36657438,\n",
       "         -0.29774617, -0.29267699,  0.39524346,  0.59984522,  0.49221136],\n",
       "        [-0.18616089,  0.00130293,  0.24020937,  0.27849233, -0.16988164,\n",
       "          0.08012462,  0.00403681, -0.63662654,  0.3572139 ,  0.50099492],\n",
       "        [-0.17690577,  0.15108906, -0.55595646, -0.17174969,  0.56711352,\n",
       "          0.19820051, -0.13459342,  0.3780365 , -0.23981781,  0.08916207],\n",
       "        [ 0.4833012 , -0.0835686 ,  0.39560413, -0.46641871,  0.26744039,\n",
       "          0.26785981, -0.36818756,  0.55628231, -0.07575553,  0.53592039]]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([[-0.65020487],\n",
       "        [-0.46633888],\n",
       "        [-0.66860056],\n",
       "        [ 0.25831627],\n",
       "        [ 0.13977006],\n",
       "        [ 0.04920237],\n",
       "        [-0.67455506],\n",
       "        [ 0.09074267],\n",
       "        [-0.25159638],\n",
       "        [ 0.0043823 ]]),\n",
       " array([ 0.])]"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.get_value() for param in policy.params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ -3.38628206e+03,  -2.71029260e+06,  -2.23740378e+02,\n",
       "           3.24032906e+02,   7.84169639e+02,   6.14002030e+04,\n",
       "          -2.16855556e+02,   1.43394391e+02,  -1.39972025e+03,\n",
       "           1.07858852e+00],\n",
       "        [ -3.90804517e+06,  -7.81069913e+07,   8.70493071e+04,\n",
       "           9.38288561e+05,   6.94381360e+05,   1.98308349e+05,\n",
       "           8.43941699e+04,   4.19861765e+04,  -2.89411837e+04,\n",
       "          -3.61929299e+02],\n",
       "        [  1.00414462e+05,  -9.70872628e+05,  -1.73246346e+03,\n",
       "          -3.71718270e+04,  -3.28545188e+04,   3.48526740e+03,\n",
       "          -6.53258312e+02,  -2.77350879e+03,   1.44247451e+04,\n",
       "           9.55770370e+00],\n",
       "        [ -1.51722105e+06,  -1.13066753e+07,  -4.95092424e+04,\n",
       "           5.91058845e+05,   5.44002070e+05,   1.08913205e+04,\n",
       "          -3.22916210e+04,   4.81845346e+04,  -3.95528720e+05,\n",
       "           2.42316391e+02]]),\n",
       " array([  1.01709805e+05,   7.45554712e+05,   3.24692216e+04,\n",
       "         -4.24526108e+04,  -4.18788374e+04,  -3.25662573e+03,\n",
       "          2.98606814e+04,  -3.69864680e+03,   4.32039531e+04,\n",
       "         -1.36717888e+02]),\n",
       " array([[-3428519.1931629 ],\n",
       "        [ 1164114.12232787],\n",
       "        [ 5336160.7825486 ],\n",
       "        [ 4000817.67819664],\n",
       "        [-4199547.03779153],\n",
       "        [ 5331997.94038703],\n",
       "        [-5368852.77016529],\n",
       "        [-4540427.97021349],\n",
       "        [ 4970524.3179658 ],\n",
       "        [ 5319318.05146773]]),\n",
       " array([-5403802.03548109])]"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient(\n",
    "    x = x0,\n",
    "    dt = 0.1, \n",
    "    C = 1,\n",
    "    Q = Q0,\n",
    "    x_t = x_t0,\n",
    "    num_steps = path_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(118406247.35960904)"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cost(\n",
    "     x = x0,\n",
    "    dt = 0.1, \n",
    "    C = 1,\n",
    "    Q = Q0,\n",
    "    x_t = x_t0,\n",
    "    num_steps = path_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano_path = sim_cartpole_T(\n",
    "    x = x0,\n",
    "    dt = 0.1, \n",
    "    C = 1,\n",
    "    Q = Q0,\n",
    "    x_t = x_t0,\n",
    "    num_steps = path_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   2.82743339e+00,  -3.10067555e-02,\n",
       "         -6.65269697e-01],\n",
       "       [ -3.10067555e-03,   2.76090642e+00,  -6.06702043e-02,\n",
       "         -1.32798427e+00],\n",
       "       [ -9.16769598e-03,   2.62810799e+00,  -9.19321233e-02,\n",
       "         -2.11502816e+00],\n",
       "       ..., \n",
       "       [ -2.79128291e+02,  -8.33340287e+02,  -1.32337141e+01,\n",
       "         -1.71993952e+01],\n",
       "       [ -2.80451662e+02,  -8.35060226e+02,  -1.22543988e+01,\n",
       "         -1.72927900e+01],\n",
       "       [ -2.81677102e+02,  -8.36789505e+02,  -1.13872279e+01,\n",
       "         -1.98342062e+01]])"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_weights = [param.get_value() for param in policy.params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reshaped_params = np.array([])\n",
    "for weight in initial_weights:\n",
    "    weight = np.transpose(weight).flatten()\n",
    "    reshaped_params = np.concatenate((reshaped_params, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.40389585, -0.18616089, -0.17690577,  0.4833012 ,  0.15987791,\n",
       "        0.00130293,  0.15108906, -0.0835686 , -0.08153353,  0.24020937,\n",
       "       -0.55595646,  0.39560413,  0.37362209,  0.27849233, -0.17174969,\n",
       "       -0.46641871,  0.36657438, -0.16988164,  0.56711352,  0.26744039,\n",
       "       -0.29774617,  0.08012462,  0.19820051,  0.26785981, -0.29267699,\n",
       "        0.00403681, -0.13459342, -0.36818756,  0.39524346, -0.63662654,\n",
       "        0.3780365 ,  0.55628231,  0.59984522,  0.3572139 , -0.23981781,\n",
       "       -0.07575553,  0.49221136,  0.50099492,  0.08916207,  0.53592039,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.65020487, -0.46633888, -0.66860056,  0.25831627,  0.13977006,\n",
       "        0.04920237, -0.67455506,  0.09074267, -0.25159638,  0.0043823 ,  0.        ])"
      ]
     },
     "execution_count": 1021,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_path = np.zeros([4, 501])\n",
    "np_path[:, 0] = x0\n",
    "u_np = np.zeros([500,])\n",
    "for t in range(500):\n",
    "    u_np[t] = simpleFeedForward(np_path[:, t], reshaped_params, 4, 10, 1)\n",
    "    np_path[:, t+1] = sim_cartpole(np_path[:,t], u_np[t], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,  -3.10067555e-03,\n",
       "         -9.16769598e-03,  -1.83609083e-02],\n",
       "       [  2.82743339e+00,   2.82743339e+00,   2.76090642e+00,\n",
       "          2.62810799e+00,   2.41660518e+00],\n",
       "       [  0.00000000e+00,  -3.10067555e-02,  -6.06702043e-02,\n",
       "         -9.19321233e-02,  -1.22322672e-01],\n",
       "       [  0.00000000e+00,  -6.65269697e-01,  -1.32798427e+00,\n",
       "         -2.11502816e+00,  -3.13173561e+00]])"
      ]
     },
     "execution_count": 1023,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_path[:, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  2.82743339, -0.03100676, -0.6652697 ]),\n",
       " array([-0.00310068,  2.76090642, -0.0606702 , -1.32798427]))"
      ]
     },
     "execution_count": 1034,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(theano_path[0])[:,0], np.transpose(theano_path[0])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  2.82743339, -0.03100676, -0.6652697 ]),\n",
       " array([-0.00310068,  2.76090642, -0.0606702 , -1.32798427]))"
      ]
     },
     "execution_count": 1029,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = np.transpose(theano_path[0])[:,0]\n",
    "\n",
    "u_1 = simpleFeedForward(x_1, reshaped_params, 4, 10, 1)\n",
    "\n",
    "x_2 = sim_cartpole(x_1, u_1, 0.1)\n",
    "\n",
    "x_1, x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  2.82743339, -0.03100676, -0.6652697 ]),\n",
       " array([-0.00310068,  2.76090642, -0.0606702 , -1.32798427]))"
      ]
     },
     "execution_count": 1031,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2_T = compute_next_step(x_1, compute_control_input(x_1), 0.1)\n",
    "\n",
    "x_1, x_2_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1045-b0d8bfad57dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpenalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m501\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1042-f989c2cd6ee8>\u001b[0m in \u001b[0;36mpenalty\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "evaluate_theta(x0, np.array([0, np.pi, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,10) and (4,) not aligned: 10 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1019-af7312420749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,10) and (4,) not aligned: 10 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    " - np.transpose(theano_path[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
